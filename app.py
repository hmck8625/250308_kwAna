import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from io import BytesIO
import os
import time
import json
import re
import base64
from openai import OpenAI
import difflib

# ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
DEBUG = True

# ãƒ‡ãƒãƒƒã‚°é–¢æ•°
def debug_info(message, expanded=False):
    """é€šå¸¸ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤º"""
    if DEBUG:
        with st.expander("ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±", expanded=expanded):
            st.write(message)

def upload_debug_info(message):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã¯å¸¸ã«è¡¨ç¤º"""
    if DEBUG:
        st.info("ğŸ“‹ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±")
        st.json(message)

# æ¨™æº–çš„ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã¨èª¬æ˜ï¼ˆæ—¥æœ¬èªã‚‚è¿½åŠ ï¼‰
STANDARD_FIELDS = {
    'Keyword': ['ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰', 'keywords', 'search term', 'æ¤œç´¢èªå¥', 'query', 'kw', 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ†ã‚­ã‚¹ãƒˆ'],
    'MatchType': ['ãƒãƒƒãƒã‚¿ã‚¤ãƒ—', 'match type', 'match', 'matching', 'ã‚¿ã‚¤ãƒ—', 'ä¸€è‡´ã‚¿ã‚¤ãƒ—', 'ä¸€è‡´ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰', 'ãƒãƒƒãƒãƒ³ã‚°ã‚¿ã‚¤ãƒ—'],
    'Impressions': ['imp', 'imps', 'impression', 'ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³', 'è¡¨ç¤ºå›æ•°', 'è¡¨ç¤ºæ•°', 'éœ²å‡ºæ•°', 'ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°'],
    'Clicks': ['click', 'ã‚¯ãƒªãƒƒã‚¯', 'ã‚¯ãƒªãƒƒã‚¯æ•°', 'ã‚¯ãƒªãƒƒã‚¯å›æ•°', 'click count', 'clicks'],
    'Cost': ['ã‚³ã‚¹ãƒˆ', 'cost', 'è²»ç”¨', 'é‡‘é¡', 'spend', 'æ”¯å‡º', 'æ¶ˆåŒ–é‡‘é¡', 'æ¶ˆåŒ–é¡'],
    'Conversions': ['conversion', 'conv', 'ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³', 'æˆç´„', 'cv', 'CVs', 'ç²å¾—æ•°', 'ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°', 'ã‚³ãƒ³ãƒæ•°', 'GACV'],
    'CampaignName': ['ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å', 'campaign', 'ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³', 'campaign name', 'ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒãƒ¼ãƒ ', 'cp', 'campname'],
    'AdGroupName': ['åºƒå‘Šã‚°ãƒ«ãƒ¼ãƒ—å', 'adgroup', 'ad group', 'åºƒå‘Šã‚°ãƒ«ãƒ¼ãƒ—', 'group name', 'ã‚°ãƒ«ãƒ¼ãƒ—å', 'adgroupname', 'ag']
}

# å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
REQUIRED_FIELDS = ['Keyword', 'MatchType', 'Impressions', 'Clicks', 'Cost', 'Conversions']

# åˆæœŸè¨­å®š
st.set_page_config(page_title="ãƒªã‚¹ãƒ†ã‚£ãƒ³ã‚°åºƒå‘Šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ", page_icon="ğŸ“Š", layout="wide")

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚¹ã‚¿ã‚¤ãƒ«
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1E88E5;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.8rem;
        font-weight: bold;
        color: #0D47A1;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .card {
        background-color: #f9f9f9;
        padding: 1.5rem;
        border-radius: 0.5rem;
        box-shadow: 0 0.15rem 0.5rem rgba(0, 0, 0, 0.1);
        margin-bottom: 1rem;
    }
    .warning {
        color: #FFA000;
        font-weight: bold;
    }
    .success {
        color: #4CAF50;
        font-weight: bold;
    }
    .info-box {
        background-color: #E3F2FD;
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
    }
    .progress-container {
        margin-top: 1rem;
        margin-bottom: 1rem;
    }
</style>
""", unsafe_allow_html=True)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'data' not in st.session_state:
    st.session_state.data = None
if 'raw_data' not in st.session_state:
    st.session_state.raw_data = None
if 'column_mapping' not in st.session_state:
    st.session_state.column_mapping = None
if 'categorized_data' not in st.session_state:
    st.session_state.categorized_data = None
if 'is_categorized' not in st.session_state:
    st.session_state.is_categorized = False
if 'categories_master' not in st.session_state:
    st.session_state.categories_master = None
if 'category_stats' not in st.session_state:
    st.session_state.category_stats = None
if 'api_key' not in st.session_state:
    st.session_state.api_key = ""
if 'service_description' not in st.session_state:
    st.session_state.service_description = ""
if 'client' not in st.session_state:
    st.session_state.client = None

# ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º
st.markdown('<div class="main-header">ãƒªã‚¹ãƒ†ã‚£ãƒ³ã‚°åºƒå‘Šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã‚·ã‚¹ãƒ†ãƒ </div>', unsafe_allow_html=True)

# OpenAIé–¢é€£ã®é–¢æ•°
def suggest_column_mapping_with_llm(df_columns, api_key):
    """LLMã‚’ä½¿ç”¨ã—ã¦åˆ—åã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ææ¡ˆã™ã‚‹"""
    if not api_key:
        return None, "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
    
    try:
        client = OpenAI(api_key=api_key)
        
        prompt = f"""
ã‚ãªãŸã¯ãƒªã‚¹ãƒ†ã‚£ãƒ³ã‚°åºƒå‘Šã®ãƒ‡ãƒ¼ã‚¿åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®Excelã®åˆ—åã‚’æ¨™æº–çš„ãªåˆ—åã«ãƒãƒƒãƒ”ãƒ³ã‚°ã—ã¦ãã ã•ã„ã€‚

å…¥åŠ›ã•ã‚ŒãŸåˆ—å:
{', '.join(df_columns)}

æ¨™æº–çš„ãªåˆ—åã®å€™è£œ:
- Keyword: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆå¿…é ˆï¼‰
- MatchType: ãƒãƒƒãƒã‚¿ã‚¤ãƒ—ï¼ˆå®Œå…¨ä¸€è‡´/ãƒ•ãƒ¬ãƒ¼ã‚ºä¸€è‡´/éƒ¨åˆ†ä¸€è‡´ãªã©ï¼‰ï¼ˆå¿…é ˆï¼‰
- Impressions: ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°ï¼ˆå¿…é ˆï¼‰
- Clicks: ã‚¯ãƒªãƒƒã‚¯æ•°ï¼ˆå¿…é ˆï¼‰
- Cost: ã‚³ã‚¹ãƒˆï¼ˆå¿…é ˆï¼‰
- Conversions: ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°ï¼ˆå¿…é ˆï¼‰
- CampaignName: ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³åï¼ˆæ¨å¥¨ï¼‰
- AdGroupName: åºƒå‘Šã‚°ãƒ«ãƒ¼ãƒ—åï¼ˆæ¨å¥¨ï¼‰

å„åˆ—åã«å¯¾ã—ã¦ã€æœ€ã‚‚é©åˆ‡ãªæ¨™æº–åˆ—åã‚’é¸ã‚“ã§ãã ã•ã„ã€‚é©åˆ‡ãªãƒãƒƒãƒ”ãƒ³ã‚°ãŒãªã„å ´åˆã¯ "unknown" ã¨ã—ã¦ãã ã•ã„ã€‚
çµæœã¯ä»¥ä¸‹ã®JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„:

```json
{
  "å…¥åŠ›åˆ—å1": "æ¨™æº–åˆ—å1",
  "å…¥åŠ›åˆ—å2": "æ¨™æº–åˆ—å2",
  ...
}
```

ã¾ãŸã€å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¨ãªã£ã¦ã„ã‚‹æ¨™æº–åˆ—åã®ã„ãšã‚Œã‹ã«é©åˆ‡ãªãƒãƒƒãƒ”ãƒ³ã‚°ãŒãªã„å ´åˆã¯ã€ãã®æ—¨ã‚‚æ•™ãˆã¦ãã ã•ã„ã€‚
"""
        
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "You are a helpful assistant specializing in data analysis."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1000,
            temperature=0.1
        )
        
        content = response.choices[0].message.content
        
        # JSONã®éƒ¨åˆ†ã‚’æŠ½å‡º
        json_match = re.search(r'```json\s*([\s\S]*?)\s*```', content)
        if json_match:
            json_str = json_match.group(1)
        else:
            json_str = content
        
        # JSONã‚’ãƒ‘ãƒ¼ã‚¹
        try:
            result = json.loads(json_str)
            return result, None
        except json.JSONDecodeError as e:
            return None, f"JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}\n\nãƒ¬ã‚¹ãƒãƒ³ã‚¹: {content}"
        
    except Exception as e:
        return None, f"APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}"

def suggest_column_mapping_with_rules(df_columns):
    """ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§åˆ—åã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ææ¡ˆã™ã‚‹"""
    mapping = {}
    
    for col in df_columns:
        col_lower = col.lower()
        matched = False
        
        for std_field, alternatives in STANDARD_FIELDS.items():
            # å®Œå…¨ä¸€è‡´
            if col_lower == std_field.lower():
                mapping[col] = std_field
                matched = True
                break
            
            # éƒ¨åˆ†ä¸€è‡´ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ã‚’åŒºåˆ¥ã—ãªã„ï¼‰
            for alt in alternatives:
                if alt.lower() in col_lower:
                    mapping[col] = std_field
                    matched = True
                    break
            
            if matched:
                break
        
        # æ–‡å­—åˆ—é¡ä¼¼åº¦ã§ãƒãƒƒãƒãƒ³ã‚°
        if not matched:
            best_match = None
            best_score = 0.7  # é–¾å€¤
            
            for std_field, alternatives in STANDARD_FIELDS.items():
                score = difflib.SequenceMatcher(None, col_lower, std_field.lower()).ratio()
                if score > best_score:
                    best_match = std_field
                    best_score = score
                
                for alt in alternatives:
                    score = difflib.SequenceMatcher(None, col_lower, alt.lower()).ratio()
                    if score > best_score:
                        best_match = std_field
                        best_score = score
            
            if best_match:
                mapping[col] = best_match
            else:
                mapping[col] = "unknown"
    
    return mapping

def create_column_mapping_ui(df, api_key=None):
    """ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°ã®UIä½œæˆ"""
    st.markdown("### åˆ—åãƒãƒƒãƒ”ãƒ³ã‚°")
    st.write("Excelã®åˆ—åã‚’æ¨™æº–çš„ãªåˆ—åã«ãƒãƒƒãƒ”ãƒ³ã‚°ã—ã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚")
    
    # LLMã¨ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ä¸¡æ–¹ã§ææ¡ˆã‚’å–å¾—
    llm_mapping = None
    if api_key:
        with st.spinner("AIã«ã‚ˆã‚‹åˆ—ååˆ†æä¸­..."):
            llm_mapping, error = suggest_column_mapping_with_llm(df.columns.tolist(), api_key)
            if error:
                st.warning(f"AIã«ã‚ˆã‚‹åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error}")
                st.write("ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®åˆ†æã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    
    # ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã«ã‚ˆã‚‹ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆLLMãŒå¤±æ•—ã—ãŸå ´åˆã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰
    rule_mapping = suggest_column_mapping_with_rules(df.columns.tolist())
    
    # æœ€çµ‚ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆLLMãŒæˆåŠŸã—ãŸå ´åˆã¯ãã‚Œã‚’å„ªå…ˆï¼‰
    final_mapping = llm_mapping if llm_mapping else rule_mapping
    
    # ãƒãƒƒãƒ”ãƒ³ã‚°ç·¨é›†UI
    st.write("ä»¥ä¸‹ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ç¢ºèªã—ã€å¿…è¦ã«å¿œã˜ã¦ä¿®æ­£ã—ã¦ãã ã•ã„ï¼š")
    
    # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¨æ¨å¥¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«åˆ†ã‘ã¦è¡¨ç¤º
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰")
        mapping_inputs_required = {}
        
        # æ¤œå‡ºã•ã‚Œã¦ã„ãªã„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½è·¡
        missing_fields = []
        
        for field in REQUIRED_FIELDS:
            # ã“ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚ŒãŸåˆ—ã‚’æ¤œç´¢
            mapped_columns = [col for col, mapped in final_mapping.items() if mapped == field]
            
            if mapped_columns:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ€åˆã«ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚ŒãŸåˆ—ã‚’é¸æŠ
                default_idx = df.columns.tolist().index(mapped_columns[0]) if mapped_columns[0] in df.columns else 0
                mapping_inputs_required[field] = st.selectbox(
                    f"{field} (å¿…é ˆ)",
                    options=["--é¸æŠã—ã¦ãã ã•ã„--"] + df.columns.tolist(),
                    index=default_idx + 1  # +1 because of the "--é¸æŠã—ã¦ãã ã•ã„--" option
                )
            else:
                # ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚ŒãŸåˆ—ãŒãªã„å ´åˆ
                missing_fields.append(field)
                mapping_inputs_required[field] = st.selectbox(
                    f"{field} (å¿…é ˆãƒ»æœªæ¤œå‡º)",
                    options=["--é¸æŠã—ã¦ãã ã•ã„--"] + df.columns.tolist(),
                    index=0
                )
    
    with col2:
        st.markdown("#### æ¨å¥¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰")
        mapping_inputs_recommended = {}
        
        recommended_fields = [f for f in STANDARD_FIELDS.keys() if f not in REQUIRED_FIELDS]
        
        for field in recommended_fields:
            # ã“ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚ŒãŸåˆ—ã‚’æ¤œç´¢
            mapped_columns = [col for col, mapped in final_mapping.items() if mapped == field]
            
            if mapped_columns:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ€åˆã«ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚ŒãŸåˆ—ã‚’é¸æŠ
                default_idx = df.columns.tolist().index(mapped_columns[0]) if mapped_columns[0] in df.columns else 0
                mapping_inputs_recommended[field] = st.selectbox(
                    f"{field} (æ¨å¥¨)",
                    options=["--ãªã—--"] + df.columns.tolist(),
                    index=default_idx + 1  # +1 because of the "--ãªã—--" option
                )
            else:
                # ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚ŒãŸåˆ—ãŒãªã„å ´åˆ
                mapping_inputs_recommended[field] = st.selectbox(
                    f"{field} (æ¨å¥¨)",
                    options=["--ãªã—--"] + df.columns.tolist(),
                    index=0
                )
    
    # æœªæ¤œå‡ºãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®è­¦å‘Š
    if missing_fields:
        st.warning(f"ä»¥ä¸‹ã®å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒè‡ªå‹•æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚é©åˆ‡ãªåˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„: {', '.join(missing_fields)}")
    
    # ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’é©ç”¨ã™ã‚‹ã‹ã©ã†ã‹
    apply_mapping = st.button("ã“ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’é©ç”¨ã™ã‚‹")
    
    if apply_mapping:
        # é¸æŠã•ã‚ŒãŸå†…å®¹ã‹ã‚‰ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
        selected_mapping = {}
        
        for field, selected in mapping_inputs_required.items():
            if selected != "--é¸æŠã—ã¦ãã ã•ã„--":
                selected_mapping[field] = selected
        
        for field, selected in mapping_inputs_recommended.items():
            if selected != "--ãªã—--":
                selected_mapping[field] = selected
        
        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ç¢ºèª
        missing = [field for field in REQUIRED_FIELDS if field not in selected_mapping]
        
        if missing:
            st.error(f"ä»¥ä¸‹ã®å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“: {', '.join(missing)}")
            return None, None
        
        # æœ€çµ‚ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’åè»¢ï¼ˆå…ƒã®åˆ—åâ†’æ¨™æº–åˆ—åï¼‰
        inverse_mapping = {selected_mapping[k]: k for k in selected_mapping}
        
        # DataFrameã«é©ç”¨
        mapped_df = df.copy()
        mapped_df = mapped_df.rename(columns=inverse_mapping)
        
        st.success("åˆ—åã®ãƒãƒƒãƒ”ãƒ³ã‚°ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        return mapped_df, selected_mapping
    
    return None, None

# LLMã«ã‚ˆã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æé–¢æ•°
def categorize_keywords_with_llm(keywords, service_description, api_key, batch_size=100):
    """LLMã‚’ä½¿ç”¨ã—ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºã™ã‚‹"""
    if not api_key:
        return None, "OpenAI API KeyãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
    
    try:
        # å…¨ã¦ã®è¦ç´ ã‚’æ–‡å­—åˆ—ã«å¤‰æ›ã—ã€ç„¡åŠ¹ãªå€¤ã‚’é™¤å¤–
        valid_keywords = []
        keyword_map = {}  # å…ƒã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å‹ã‚’ä¿æŒã™ã‚‹ãŸã‚ã®ãƒãƒƒãƒ—
        
        for kw in keywords:
            # Noneã€ç©ºæ–‡å­—åˆ—ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if kw is not None and str(kw).strip() != '':
                kw_str = str(kw)
                valid_keywords.append(kw_str)
                keyword_map[kw_str] = kw  # å…ƒã®ãƒ‡ãƒ¼ã‚¿å‹ã‚’ä¿æŒ
        
        # æœ‰åŠ¹ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒãªã„å ´åˆ
        if not valid_keywords:
            return [], "æœ‰åŠ¹ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
        
        client = OpenAI(api_key=api_key)
        
        prompt = f"""
ã‚ãªãŸã¯ãƒªã‚¹ãƒ†ã‚£ãƒ³ã‚°åºƒå‘Šã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‚’åˆ†æã—ã€2ã¤ã®è¦³ç‚¹ã§åˆ†é¡ã—ã¦ãã ã•ã„ã€‚

ã‚µãƒ¼ãƒ“ã‚¹æ¦‚è¦:
{service_description}

ä»¥ä¸‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’åˆ†æã—ã¦ãã ã•ã„:
{', '.join(valid_keywords[:batch_size])}  # ãƒãƒƒãƒã‚µã‚¤ã‚ºã§åˆ¶é™

å„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä»¥ä¸‹ã®2ã¤ã®è¦³ç‚¹ã§åˆ†é¡ã—ã€JSONã§è¿”ã—ã¦ãã ã•ã„:
1. è»¸ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: ã‚µãƒ¼ãƒ“ã‚¹ã®æ ¸ã¨ãªã‚‹ä¸»è¦æ¦‚å¿µãƒ»æ©Ÿèƒ½ï¼ˆ5-8ã‚«ãƒ†ã‚´ãƒªç¨‹åº¦ï¼‰
2. æ›ã‘åˆã‚ã›ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: æ¤œç´¢æ„å›³ã€ä¿®é£¾èªã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‹ãƒ¼ã‚ºãªã©ï¼ˆ5-8ã‚«ãƒ†ã‚´ãƒªç¨‹åº¦ï¼‰

ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:
```json
[
  {{
    "keyword": "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1",
    "axis_category": "ã‚«ãƒ†ã‚´ãƒªA",
    "combination_category": "ã‚«ãƒ†ã‚´ãƒªX"
  }},
  {{
    "keyword": "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2",
    "axis_category": "ã‚«ãƒ†ã‚´ãƒªB",
    "combination_category": "ã‚«ãƒ†ã‚´ãƒªY"
  }}
]
```

ã‚«ãƒ†ã‚´ãƒªåã¯ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã„ã‚‚ã®ã«ã—ã¦ãã ã•ã„ã€‚
"""
        
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "You are a helpful assistant that specializes in keyword analysis for advertising."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=4000,
            temperature=0.3
        )
        
        content = response.choices[0].message.content
        
        # JSONã®éƒ¨åˆ†ã‚’æŠ½å‡º
        json_match = re.search(r'```json\s*([\s\S]*?)\s*```', content)
        if json_match:
            json_str = json_match.group(1)
        else:
            json_str = content
        
        # JSONã‚’ãƒ‘ãƒ¼ã‚¹
        try:
            result = json.loads(json_str)
            
            # çµæœã®å„ã‚¢ã‚¤ãƒ†ãƒ ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…ƒã®å€¤ã«ç½®ãæ›ãˆ
            for item in result:
                if item['keyword'] in keyword_map:
                    # å…ƒã®ãƒ‡ãƒ¼ã‚¿å‹ï¼ˆæ–‡å­—åˆ—ã¾ãŸã¯æ•°å€¤ï¼‰ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
                    item['keyword'] = keyword_map[item['keyword']]
            
            return result, None
        except json.JSONDecodeError as e:
            return None, f"JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}\n\nãƒ¬ã‚¹ãƒãƒ³ã‚¹: {content}"
        
    except Exception as e:
        return None, f"APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}"

# ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ã«å¤±æ•—ã—ãŸå ´åˆã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ã—ã¦ã®LLMã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
def cluster_keywords_with_llm(keywords, service_description, api_key, suggested_clusters=5):
    """LLMã‚’ä½¿ç”¨ã—ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹"""
    if not api_key:
        return None, None, "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
    
    # ç©ºã‚„ç„¡åŠ¹ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    valid_keywords = []
    keyword_map = {}  # å…ƒã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å‹ã‚’ä¿æŒã™ã‚‹ãŸã‚ã®ãƒãƒƒãƒ—
    
    for kw in keywords:
        if kw is not None and str(kw).strip() != '':
            kw_str = str(kw)
            valid_keywords.append(kw_str)
            keyword_map[kw_str] = kw  # å…ƒã®ãƒ‡ãƒ¼ã‚¿å‹ã‚’ä¿æŒ
    
    # æœ‰åŠ¹ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒãªã„å ´åˆ
    if not valid_keywords:
        dummy_result = []
        return dummy_result, "æœ‰åŠ¹ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
    
    try:
        client = OpenAI(api_key=api_key)
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°ã®è‡ªå‹•èª¿æ•´ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°ã«å¿œã˜ã¦ï¼‰
        cluster_count = min(suggested_clusters, max(2, len(valid_keywords) // 5))
        
        prompt = f"""
ã‚ãªãŸã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‚’åˆ†æã—ã€æ„å‘³çš„ã«é–¢é€£ã™ã‚‹ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†é¡ã—ã¦ãã ã•ã„ã€‚

ã‚µãƒ¼ãƒ“ã‚¹æ¦‚è¦:
{service_description}

ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ:
{', '.join(valid_keywords)}

åˆ†æã‚¿ã‚¹ã‚¯:
1. å„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã€Œè»¸ã‚«ãƒ†ã‚´ãƒªã€ã¨ã€Œæ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒªã€ã®2ã¤ã®è¦³ç‚¹ã§åˆ†é¡ã—ã¦ãã ã•ã„ã€‚
   - è»¸ã‚«ãƒ†ã‚´ãƒª: ã‚µãƒ¼ãƒ“ã‚¹ã®æ ¸ã¨ãªã‚‹ä¸»è¦æ¦‚å¿µãƒ»æ©Ÿèƒ½ï¼ˆ{cluster_count}å€‹ç¨‹åº¦ï¼‰
   - æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒª: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¤œç´¢æ„å›³ã‚„ä¿®é£¾èªï¼ˆ{cluster_count}å€‹ç¨‹åº¦ï¼‰

2. ä»¥ä¸‹ã®JSONå½¢å¼ã§çµæœã‚’è¿”ã—ã¦ãã ã•ã„:
```json
[
  {{
    "keyword": "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1",
    "axis_category": "è»¸ã‚«ãƒ†ã‚´ãƒªA",
    "combination_category": "æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒªX"
  }},
  {{
    "keyword": "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2",
    "axis_category": "è»¸ã‚«ãƒ†ã‚´ãƒªB",
    "combination_category": "æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒªY"
  }}
]
```

ã‚«ãƒ†ã‚´ãƒªåã¯ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã„ã‚‚ã®ã«ã—ã¦ãã ã•ã„ã€‚
å„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯å¿…ãšã„ãšã‚Œã‹ã®è»¸ã‚«ãƒ†ã‚´ãƒªã¨æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡ã—ã¦ãã ã•ã„ã€‚
"""
        
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "You are a keyword analysis expert specializing in clustering and categorization."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=4000,
            temperature=0.3
        )
        
        content = response.choices[0].message.content
        
        # JSONã®éƒ¨åˆ†ã‚’æŠ½å‡º
        json_match = re.search(r'```json\s*([\s\S]*?)\s*```', content)
        if json_match:
            json_str = json_match.group(1)
        else:
            json_str = content
        
        # JSONã‚’ãƒ‘ãƒ¼ã‚¹
        try:
            result = json.loads(json_str)
            
            # çµæœã®å„ã‚¢ã‚¤ãƒ†ãƒ ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…ƒã®å€¤ã«ç½®ãæ›ãˆ
            for item in result:
                if item['keyword'] in keyword_map:
                    item['keyword'] = keyword_map[item['keyword']]  # å…ƒã®ãƒ‡ãƒ¼ã‚¿å‹ã‚’ä½¿ç”¨
            
            return result, None
        except json.JSONDecodeError as e:
            return None, f"JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}\n\nãƒ¬ã‚¹ãƒãƒ³ã‚¹: {content}"
        
    except Exception as e:
        return None, f"LLMã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}"

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("è¨­å®š")
    api_key = st.text_input("OpenAI API Key", st.session_state.api_key, type="password")
    if api_key:
        st.session_state.api_key = api_key
        os.environ["OPENAI_API_KEY"] = api_key
        # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        try:
            st.session_state.client = OpenAI(api_key=api_key)
            st.success("APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¾ã—ãŸ")
        except Exception as e:
            st.error(f"APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    st.markdown("### ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å‡¦ç†è¨­å®š")
    cost_threshold = st.slider("ã‚³ã‚¹ãƒˆä¸Šä½ã‚«ãƒãƒ¼ç‡ (%)", 50, 100, 80)
    max_keywords_per_batch = st.slider("ãƒãƒƒãƒã‚ãŸã‚Šæœ€å¤§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°", 50, 500, 100)
    
    st.markdown("### åˆ†æè¨­å®š")
    kw_min_cost = st.number_input("æœ€å°ã‚³ã‚¹ãƒˆé–¾å€¤ (å††)", 0, 1000000, 1000)
    min_clicks = st.number_input("æœ€å°ã‚¯ãƒªãƒƒã‚¯æ•°", 0, 1000, 10)
    
    st.markdown("### ã‚µãƒ¼ãƒ“ã‚¹èª¬æ˜")
    st.session_state.service_description = st.text_area(
        "ã‚µãƒ¼ãƒ“ã‚¹ã®æ¦‚è¦ã‚’è¨˜å…¥ã—ã¦ãã ã•ã„ï¼ˆAIã«ã‚ˆã‚‹ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºã®ç²¾åº¦å‘ä¸Šã«å½¹ç«‹ã¡ã¾ã™ï¼‰",
        st.session_state.service_description, 
        height=150
    )
    
    # APIæ¥ç¶šãƒ†ã‚¹ãƒˆ
    if st.button("APIæ¥ç¶šãƒ†ã‚¹ãƒˆ"):
        if not st.session_state.api_key:
            st.error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        else:
            try:
                client = OpenAI(api_key=st.session_state.api_key)
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": "ã“ã‚“ã«ã¡ã¯"}],
                    max_tokens=10
                )
                st.success(f"APIæ¥ç¶šæˆåŠŸï¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {response.choices[0].message.content}")
            except Exception as e:
                st.error(f"APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}")

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
tab1, tab2, tab3, tab4 = st.tabs(["ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚º", "åˆ†æçµæœ", "ãƒ¬ãƒãƒ¼ãƒˆ"])

# ã‚¿ãƒ–1: ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
with tab1:
    st.markdown('<div class="sub-header">ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</div>', unsafe_allow_html=True)
    
    with st.expander("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆèª¬æ˜", expanded=False):
        st.markdown("""
        ### å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
        ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹Excelã«ã¯ä»¥ä¸‹ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå¿…è¦ã§ã™ï¼š
        - **Keyword**: åˆ†æå¯¾è±¡ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        - **MatchType**: ãƒãƒƒãƒã‚¿ã‚¤ãƒ—ï¼ˆå®Œå…¨ä¸€è‡´/ãƒ•ãƒ¬ãƒ¼ã‚ºä¸€è‡´/éƒ¨åˆ†ä¸€è‡´ãªã©ï¼‰
        - **Impressions**: ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°
        - **Clicks**: ã‚¯ãƒªãƒƒã‚¯æ•°
        - **Cost**: ã‚³ã‚¹ãƒˆ
        - **Conversions**: ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°
        
        ### æ¨å¥¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
        - **CampaignName**: ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å
        - **AdGroupName**: åºƒå‘Šã‚°ãƒ«ãƒ¼ãƒ—å
        
        ### ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹
        | Keyword | MatchType | Impressions | Clicks | Cost | Conversions | CampaignName | AdGroupName |
        |---------|-----------|-------------|--------|------|-------------|--------------|-------------|
        | ãƒªã‚¹ãƒ†ã‚£ãƒ³ã‚° åºƒå‘Š | ãƒ•ãƒ¬ãƒ¼ã‚ºä¸€è‡´ | 1200 | 120 | 24000 | 5 | ãƒ–ãƒ©ãƒ³ãƒ‰ | ãƒ¡ã‚¤ãƒ³ |
        
        â€» ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åãŒç•°ãªã‚‹å ´åˆã§ã‚‚ã€AIãŒè‡ªå‹•çš„ã«è­˜åˆ¥ãƒ»ãƒãƒƒãƒ”ãƒ³ã‚°ã—ã¾ã™ã€‚
        """)
    
    st.write("### ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å ´åˆã®å¯¾å‡¦æ³•")
    st.markdown("""
    ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã«ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å ´åˆï¼š
    
    1. **ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®ç¢ºèª**: ãƒ•ã‚¡ã‚¤ãƒ«ãŒ200MBä»¥ä¸‹ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„
    2. **åˆ¥ã®ãƒ–ãƒ©ã‚¦ã‚¶ã§è©¦ã™**: Chromeã€Firefoxã€Edgeãªã©åˆ¥ã®ãƒ–ãƒ©ã‚¦ã‚¶ã§è©¦ã—ã¦ã¿ã¦ãã ã•ã„
    3. **ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ•ã‚¡ã‚¤ãƒ«ã§è©¦ã™**: å°‘é‡ã®ãƒ‡ãƒ¼ã‚¿ã ã‘ã‚’å«ã‚€æ–°ã—ã„Excelãƒ•ã‚¡ã‚¤ãƒ«ã§è©¦ã—ã¦ãã ã•ã„
    4. **ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼**: .xlsxå½¢å¼ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„
    """)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’å¼·åŒ–
    try:
        uploaded_file = st.file_uploader("Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (.xlsx)", type=['xlsx'])
        
        if uploaded_file is not None:
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’å¸¸ã«è¡¨ç¤º
            file_info = {
                "ãƒ•ã‚¡ã‚¤ãƒ«å": uploaded_file.name,
                "ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º": f"{len(uploaded_file.getvalue())} bytes",
                "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—": uploaded_file.type
            }
            upload_debug_info(file_info)
            
            try:
                # BytesIOã‚’ä½¿ã£ã¦ãƒ¡ãƒ¢ãƒªä¸Šã§å‡¦ç†
                bytes_data = uploaded_file.getvalue()
                with BytesIO(bytes_data) as data:
                    # ã‚¨ãƒ³ã‚¸ãƒ³ã‚’æ˜ç¤ºçš„ã«æŒ‡å®šã—ã€ã‚¨ãƒ©ãƒ¼ã‚’è©³ç´°ã«è¡¨ç¤º
                    raw_df = pd.read_excel(data, engine='openpyxl')
                
                # åˆ—æƒ…å ±ã‚’å¸¸ã«è¡¨ç¤º
                st.write("æ¤œå‡ºã•ã‚ŒãŸåˆ—:", list(raw_df.columns))
                
                # å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
                st.session_state.raw_data = raw_df
                
                # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°UIè¡¨ç¤º
                mapped_df, column_mapping = create_column_mapping_ui(raw_df, st.session_state.api_key)
                
                if mapped_df is not None and column_mapping is not None:
                    # ãƒãƒƒãƒ”ãƒ³ã‚°æƒ…å ±ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
                    st.session_state.column_mapping = column_mapping
                    
                    # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªã¨å¤‰æ›
                    numeric_columns = ['Impressions', 'Clicks', 'Cost', 'Conversions']
                    for col in numeric_columns:
                        if mapped_df[col].dtype == 'object':
                            mapped_df[col] = pd.to_numeric(mapped_df[col].astype(str).str.replace(',', '').str.replace('Â¥', ''), errors='coerce')
                    
                    # æ´¾ç”ŸæŒ‡æ¨™ã®è¨ˆç®—
                    mapped_df['CTR'] = (mapped_df['Clicks'] / mapped_df['Impressions'] * 100).round(2)
                    mapped_df['CVR'] = (mapped_df['Conversions'] / mapped_df['Clicks'] * 100).round(2)
                    mapped_df['CPC'] = (mapped_df['Cost'] / mapped_df['Clicks']).round(0)
                    mapped_df['CPA'] = (mapped_df['Cost'] / mapped_df['Conversions']).round(0)
                    mapped_df['CPM'] = (mapped_df['Cost'] / mapped_df['Impressions'] * 1000).round(0)
                    
                    # ç„¡é™å€¤ã‚’NaNã«ç½®ãæ›ãˆ
                    mapped_df.replace([float('inf'), -float('inf')], np.nan, inplace=True)
                    
                    # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                    st.session_state.data = mapped_df
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
                    st.markdown('<div class="sub-header">ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼</div>', unsafe_allow_html=True)
                    st.dataframe(mapped_df.head(10))
                    
                    # åŸºæœ¬çµ±è¨ˆæƒ…å ±
                    st.markdown('<div class="sub-header">åŸºæœ¬çµ±è¨ˆæƒ…å ±</div>', unsafe_allow_html=True)
                    
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°", f"{len(mapped_df):,}")
                    
                    with col2:
                        st.metric("ç·ã‚³ã‚¹ãƒˆ", f"Â¥{mapped_df['Cost'].sum():,.0f}")
                    
                    with col3:
                        st.metric("ç·ã‚¯ãƒªãƒƒã‚¯æ•°", f"{mapped_df['Clicks'].sum():,.0f}")
                    
                    with col4:
                        st.metric("ç·ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°", f"{mapped_df['Conversions'].sum():,.0f}")
                    
                    st.success("ãƒ‡ãƒ¼ã‚¿ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸï¼ã€Œã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºã€ã‚¿ãƒ–ã«é€²ã‚“ã§ãã ã•ã„ã€‚")
            
            except Exception as e:
                st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                st.exception(e)  # ã‚ˆã‚Šè©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¡¨ç¤º
                
                # è¿½åŠ ã®ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º
                st.warning("""
                **ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼š**
                - ãƒ•ã‚¡ã‚¤ãƒ«ãŒå£Šã‚Œã¦ã„ãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„
                - åˆ¥ã®Excelãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ä¿å­˜ã—ç›´ã—ã¦ã¿ã¦ãã ã•ã„
                - ãƒ•ã‚¡ã‚¤ãƒ«å†…ã«ç‰¹æ®Šãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚„æ•°å¼ãŒã‚ã‚‹å ´åˆã¯å˜ç´”ãªå€¤ã«å¤‰æ›ã—ã¦ãã ã•ã„
                """)
    
    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.exception(e)
        
        # ä»£æ›¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ–¹æ³•ã®ææ¡ˆ
        st.warning("""
        **ä»£æ›¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ–¹æ³•:**
        1. ãƒ•ã‚¡ã‚¤ãƒ«ã‚’CSVå½¢å¼ã§ä¿å­˜ã—ç›´ã—ã¦ã¿ã¦ãã ã•ã„
        2. ãƒ‡ãƒ¼ã‚¿é‡ã‚’æ¸›ã‚‰ã—ãŸç°¡æ˜“ç‰ˆãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ†ã‚¹ãƒˆã—ã¦ãã ã•ã„
        """)
    else:
        st.info("Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

# ã‚¿ãƒ–2: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚º
with tab2:
    st.markdown('<div class="sub-header">ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚º</div>', unsafe_allow_html=True)
    
    if st.session_state.data is None:
        st.warning("å…ˆã«ã€Œãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€ã‚¿ãƒ–ã§ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        df = st.session_state.data
        
        if not st.session_state.is_categorized:
            with st.expander("ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºæ–¹æ³•", expanded=True):
                st.markdown("""
                ### ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºã®ä»•çµ„ã¿
                
                ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ä»¥ä¸‹ã®æ–¹æ³•ã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºã—ã¾ã™ï¼š
                
                1. **ã‚³ã‚¹ãƒˆã«ã‚ˆã‚‹å„ªå…ˆé †ä½ä»˜ã‘**ï¼šã‚³ã‚¹ãƒˆé †ã«ä¸Šä½ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å„ªå…ˆçš„ã«å‡¦ç†
                2. **ãƒãƒƒãƒå‡¦ç†**ï¼šå¤§é‡ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å°ã•ãªãƒãƒƒãƒã«åˆ†å‰²ã—ã¦å‡¦ç†
                3. **AIåˆ†æ**ï¼šOpenAIã®GPTãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦æ„å‘³ãƒ™ãƒ¼ã‚¹ã®ã‚«ãƒ†ã‚´ãƒªåˆ†é¡
                
                ã‚«ãƒ†ã‚´ãƒªã¯2ç¨®é¡ä½œæˆã•ã‚Œã¾ã™ï¼š
                - **è»¸ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**ï¼šã‚µãƒ¼ãƒ“ã‚¹ã®æ ¸ã¨ãªã‚‹ä¸»è¦æ¦‚å¿µãƒ»æ©Ÿèƒ½
                - **æ›ã‘åˆã‚ã›ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**ï¼šæ¤œç´¢æ„å›³ã€ä¿®é£¾èªã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‹ãƒ¼ã‚ºãªã©
                """)
            
            categorize_button = st.button("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºã‚’é–‹å§‹")
            
            if categorize_button:
                if not st.session_state.api_key:
                    st.error("OpenAI API KeyãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šã—ã¦ãã ã•ã„ã€‚")
                else:
                    # APIæ¥ç¶šãƒ†ã‚¹ãƒˆ
                    try:
                        with st.spinner("APIæ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆä¸­..."):
                            client = OpenAI(api_key=st.session_state.api_key)
                            test_response = client.chat.completions.create(
                                model="gpt-3.5-turbo",
                                messages=[{"role": "user", "content": "ãƒ†ã‚¹ãƒˆ"}],
                                max_tokens=5
                            )
                            debug_info(f"APIæ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ: {test_response.choices[0].message.content}")
                    except Exception as e:
                        st.error(f"APIæ¥ç¶šãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                        st.stop()
                    
                    # å‰å‡¦ç† - ã‚³ã‚¹ãƒˆé †ã«ä¸¦ã¹ã‚‹
                    sorted_df = df.sort_values('Cost', ascending=False)
                    total_cost = sorted_df['Cost'].sum()
                    
                    # ã‚³ã‚¹ãƒˆä¸Šä½ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼ˆé–¾å€¤ã¾ã§ã®ç´¯ç©ã‚³ã‚¹ãƒˆã§åˆ¤æ–­ï¼‰
                    sorted_df['cumulative_cost'] = sorted_df['Cost'].cumsum()
                    sorted_df['cumulative_cost_percent'] = sorted_df['cumulative_cost'] / total_cost * 100
                    high_cost_df = sorted_df[sorted_df['cumulative_cost_percent'] <= cost_threshold]
                    
                    total_keywords = len(high_cost_df)
                    
                    if total_keywords > 5000:
                        st.warning(f"å‡¦ç†ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°ãŒå¤šã„ãŸã‚({total_keywords}ä»¶)ã€å‡¦ç†ã«æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚")
                    
                    st.info(f"ã‚³ã‚¹ãƒˆä¸Šä½{cost_threshold}%ã‚’ã‚«ãƒãƒ¼ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰{total_keywords}ä»¶ã‚’å‡¦ç†ã—ã¾ã™ã€‚")
                    
                    # é€²æ—ãƒãƒ¼
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    # ä¸€æ„ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
                    unique_keywords = []
                    for kw in high_cost_df['Keyword'].unique():
                        if kw is not None and str(kw).strip() != '':
                            unique_keywords.append(kw)
                    
                    total_unique = len(unique_keywords)
                    
                    debug_info(f"ä¸€æ„ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°: {total_unique}")
                    
                    # ç©ºã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒã‚§ãƒƒã‚¯
                    if not unique_keywords:
                        st.error("æœ‰åŠ¹ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                        st.stop()
                    
                    # ãƒãƒƒãƒã«åˆ†å‰²
                    batch_size = min(max_keywords_per_batch, 100)  # å®‰å…¨ã®ãŸã‚ã«100ä»¶ã«åˆ¶é™
                    batches = [unique_keywords[i:i+batch_size] for i in range(0, len(unique_keywords), batch_size)]
                    
                    debug_info(f"ãƒãƒƒãƒæ•°: {len(batches)}, ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}")
                    
                    # çµæœä¿å­˜ç”¨
                    all_categorized = []
                    errors = []
                    
                    # ãƒãƒƒãƒå‡¦ç†
                    for i, batch in enumerate(batches):
                        status_text.text(f"ãƒãƒƒãƒ {i+1}/{len(batches)} å‡¦ç†ä¸­... ({len(batch)}ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰)")
                        
                        # LLMã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚º
                        result, error = categorize_keywords_with_llm(
                            batch,
                            st.session_state.service_description,
                            st.session_state.api_key
                        )
                        
                        if error:
                            debug_info(f"ãƒãƒƒãƒ {i+1} ã‚¨ãƒ©ãƒ¼: {error}")
                            
                            # ãƒãƒƒãƒå‡¦ç†å¤±æ•—æ™‚ã¯ã€ä»£æ›¿LLMã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã§å‡¦ç†
                            status_text.text(f"ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºå¤±æ•—ã®ãŸã‚ã€ä»£æ›¿AIã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œä¸­...")
                            
                            # LLMã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
                            backup_result, backup_error = cluster_keywords_with_llm(
                                batch, 
                                st.session_state.service_description,
                                st.session_state.api_key
                            )
                            
                            if backup_error:
                                debug_info(f"ä»£æ›¿AIã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã§ã‚‚ã‚¨ãƒ©ãƒ¼: {backup_error}")
                                # æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªå‡¦ç†ï¼šå…¨ã¦åŒã˜ã‚«ãƒ†ã‚´ãƒªã«
                                temp_categorized = []
                                for kw in batch:
                                    if kw is not None and str(kw).strip() != '':
                                        temp_categorized.append({
                                            "keyword": kw,
                                            "axis_category": "æœªåˆ†é¡ã‚°ãƒ«ãƒ¼ãƒ—",
                                            "combination_category": "è‡ªå‹•åˆ†é¡"
                                        })
                                all_categorized.extend(temp_categorized)
                                errors.append(f"ãƒãƒƒãƒ {i+1} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {error}, ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‡¦ç†ã‚‚ã‚¨ãƒ©ãƒ¼: {backup_error}")
                            else:
                                debug_info(f"ãƒãƒƒãƒ {i+1} ä»£æ›¿ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æˆåŠŸ: {len(backup_result)}ä»¶å‡¦ç†")
                                all_categorized.extend(backup_result)
                                errors.append(f"ãƒãƒƒãƒ {i+1} é€šå¸¸å‡¦ç†ã‚¨ãƒ©ãƒ¼: {error}ã€ä»£æ›¿å‡¦ç†ã§å›å¾©")
                        else:
                            debug_info(f"ãƒãƒƒãƒ {i+1} æˆåŠŸ: {len(result)}ä»¶ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å‡¦ç†")
                            all_categorized.extend(result)
                        
                        # é€²æ—æ›´æ–°
                        progress = min(1.0, (i + 1) / len(batches))
                        progress_bar.progress(progress)
                        
                        # APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«å¯¾å¿œã™ã‚‹ãŸã‚ã®å¾…æ©Ÿ
                        time.sleep(0.5)
                    
                    # ã‚«ãƒ†ã‚´ãƒªãƒã‚¹ã‚¿ã®ä½œæˆ
                    categories_df = pd.DataFrame(all_categorized)
                    
                    # å…ƒã®ãƒ‡ãƒ¼ã‚¿ã¨ãƒãƒ¼ã‚¸
                    categorized_data = df.copy()
                    category_map = {row['keyword']: {'axis': row['axis_category'], 'combination': row['combination_category']} 
                                    for _, row in categories_df.iterrows()}
                    
                    # ã‚«ãƒ†ã‚´ãƒªã®é©ç”¨é–¢æ•°
                    def apply_categories(keyword):
                        if keyword in category_map:
                            return category_map[keyword]['axis'], category_map[keyword]['combination']
                        else:
                            return "æœªåˆ†é¡", "æœªåˆ†é¡"
                    
                    # ã‚«ãƒ†ã‚´ãƒªã®é©ç”¨
                    categorized_data[['AxisCategory', 'CombinationCategory']] = categorized_data.apply(
                        lambda row: pd.Series(apply_categories(row['Keyword'])), axis=1
                    )
                    
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
                    st.session_state.categorized_data = categorized_data
                    st.session_state.categories_master = categories_df
                    st.session_state.is_categorized = True
                    
                    # ã‚«ãƒ†ã‚´ãƒªåŸºæœ¬çµ±è¨ˆ
                    axis_categories = categorized_data['AxisCategory'].nunique()
                    combination_categories = categorized_data['CombinationCategory'].nunique()
                    
                    status_text.text(f"ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºå®Œäº†ï¼è»¸ã‚«ãƒ†ã‚´ãƒªæ•°: {axis_categories}, æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒªæ•°: {combination_categories}")
                    
                    if errors:
                        with st.expander("å‡¦ç†ä¸­ã«ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼", expanded=False):
                            for error in errors:
                                st.error(error)
                    
                    st.success("ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºãŒå®Œäº†ã—ã¾ã—ãŸï¼ã€Œåˆ†æçµæœã€ã‚¿ãƒ–ã«é€²ã‚“ã§ãã ã•ã„ã€‚")
        else:
            st.success("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºã¯å®Œäº†ã—ã¦ã„ã¾ã™ã€‚")
            
            # ã‚«ãƒ†ã‚´ãƒªãƒã‚¹ã‚¿ã®è¡¨ç¤º
            st.markdown('<div class="sub-header">ã‚«ãƒ†ã‚´ãƒªãƒã‚¹ã‚¿</div>', unsafe_allow_html=True)
            
            tab_master1, tab_master2 = st.tabs(["è»¸ã‚«ãƒ†ã‚´ãƒª", "æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒª"])
            
            with tab_master1:
                axis_counts = st.session_state.categorized_data['AxisCategory'].value_counts().reset_index()
                axis_counts.columns = ['è»¸ã‚«ãƒ†ã‚´ãƒª', 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°']
                st.dataframe(axis_counts)
                
                # å††ã‚°ãƒ©ãƒ•
                fig = px.pie(axis_counts, values='ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°', names='è»¸ã‚«ãƒ†ã‚´ãƒª', title='è»¸ã‚«ãƒ†ã‚´ãƒªã®åˆ†å¸ƒ')
                st.plotly_chart(fig)
            
            with tab_master2:
                combination_counts = st.session_state.categorized_data['CombinationCategory'].value_counts().reset_index()
                combination_counts.columns = ['æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒª', 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°']
                st.dataframe(combination_counts)
                
                # å††ã‚°ãƒ©ãƒ•
                fig = px.pie(combination_counts, values='ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°', names='æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒª', title='æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒªã®åˆ†å¸ƒ')
                st.plotly_chart(fig)
            
            # ãƒªã‚»ãƒƒãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³
            if st.button("ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºã‚’ãƒªã‚»ãƒƒãƒˆ"):
                st.session_state.is_categorized = False
                st.session_state.categorized_data = None
                st.session_state.categories_master = None
                st.session_state.category_stats = None
                st.success("ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºãƒ‡ãƒ¼ã‚¿ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã¾ã—ãŸã€‚å¿…è¦ã«å¿œã˜ã¦å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                st.experimental_rerun()

# ã‚¿ãƒ–3: åˆ†æçµæœ
with tab3:
    st.markdown('<div class="sub-header">ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ</div>', unsafe_allow_html=True)
    
    if not st.session_state.is_categorized:
        st.warning("å…ˆã«ã€Œã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºã€ã‚¿ãƒ–ã§ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    else:
        categorized_data = st.session_state.categorized_data
        
        if 'category_stats' not in st.session_state or st.session_state.category_stats is None:
            # ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆã®åˆå›è¨ˆç®—
            with st.spinner("ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é›†è¨ˆä¸­..."):
                # 1. è»¸ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ
                axis_stats = categorized_data.groupby('AxisCategory').agg({
                    'Keyword': 'count',
                    'Impressions': 'sum',
                    'Clicks': 'sum',
                    'Cost': 'sum',
                    'Conversions': 'sum'
                }).reset_index()
                
                # æ´¾ç”ŸæŒ‡æ¨™ã®è¨ˆç®—
                axis_stats['CTR'] = (axis_stats['Clicks'] / axis_stats['Impressions'] * 100).round(2)
                axis_stats['CVR'] = (axis_stats['Conversions'] / axis_stats['Clicks'] * 100).round(2)
                axis_stats['CPC'] = (axis_stats['Cost'] / axis_stats['Clicks']).round(0)
                axis_stats['CPA'] = (axis_stats['Cost'] / axis_stats['Conversions']).round(0)
                
                # ãƒ©ãƒ™ãƒ«å¤‰æ›´
                axis_stats.rename(columns={'Keyword': 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°'}, inplace=True)
                
                # 2. æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ
                combination_stats = categorized_data.groupby('CombinationCategory').agg({
                    'Keyword': 'count',
                    'Impressions': 'sum',
                    'Clicks': 'sum',
                    'Cost': 'sum',
                    'Conversions': 'sum'
                }).reset_index()
                
                # æ´¾ç”ŸæŒ‡æ¨™ã®è¨ˆç®—
                combination_stats['CTR'] = (combination_stats['Clicks'] / combination_stats['Impressions'] * 100).round(2)
                combination_stats['CVR'] = (combination_stats['Conversions'] / combination_stats['Clicks'] * 100).round(2)
                combination_stats['CPC'] = (combination_stats['Cost'] / combination_stats['Clicks']).round(0)
                combination_stats['CPA'] = (combination_stats['Cost'] / combination_stats['Conversions']).round(0)
                
                # ãƒ©ãƒ™ãƒ«å¤‰æ›´
                combination_stats.rename(columns={'Keyword': 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°'}, inplace=True)
                
                # 3. ã‚¯ãƒ­ã‚¹é›†è¨ˆï¼ˆè»¸Ã—æ›ã‘åˆã‚ã›ï¼‰
                cross_stats = categorized_data.groupby(['AxisCategory', 'CombinationCategory']).agg({
                    'Keyword': 'count',
                    'Impressions': 'sum',
                    'Clicks': 'sum',
                    'Cost': 'sum',
                    'Conversions': 'sum'
                }).reset_index()
                
                # æ´¾ç”ŸæŒ‡æ¨™ã®è¨ˆç®—
                cross_stats['CTR'] = (cross_stats['Clicks'] / cross_stats['Impressions'] * 100).round(2)
                cross_stats['CVR'] = (cross_stats['Conversions'] / cross_stats['Clicks'] * 100).round(2)
                cross_stats['CPC'] = (cross_stats['Cost'] / cross_stats['Clicks']).round(0)
                cross_stats['CPA'] = (cross_stats['Cost'] / cross_stats['Conversions']).round(0)
                
                # ãƒ©ãƒ™ãƒ«å¤‰æ›´
                cross_stats.rename(columns={'Keyword': 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°'}, inplace=True)
                
                # 4. ãƒãƒƒãƒã‚¿ã‚¤ãƒ—åˆ¥é›†è¨ˆ
                match_type_stats = categorized_data.groupby('MatchType').agg({
                    'Keyword': 'count',
                    'Impressions': 'sum',
                    'Clicks': 'sum',
                    'Cost': 'sum',
                    'Conversions': 'sum'
                }).reset_index()
                
                # æ´¾ç”ŸæŒ‡æ¨™ã®è¨ˆç®—
                match_type_stats['CTR'] = (match_type_stats['Clicks'] / match_type_stats['Impressions'] * 100).round(2)
                match_type_stats['CVR'] = (match_type_stats['Conversions'] / match_type_stats['Clicks'] * 100).round(2)
                match_type_stats['CPC'] = (match_type_stats['Cost'] / match_type_stats['Clicks']).round(0)
                match_type_stats['CPA'] = (match_type_stats['Cost'] / match_type_stats['Conversions']).round(0)
                
                # ãƒ©ãƒ™ãƒ«å¤‰æ›´
                match_type_stats.rename(columns={'Keyword': 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°'}, inplace=True)
                
                # 5. è»¸ã‚«ãƒ†ã‚´ãƒªÃ—ãƒãƒƒãƒã‚¿ã‚¤ãƒ—ã®ã‚¯ãƒ­ã‚¹é›†è¨ˆ
                axis_match_type_stats = categorized_data.groupby(['AxisCategory', 'MatchType']).agg({
                    'Keyword': 'count',
                    'Impressions': 'sum',
                    'Clicks': 'sum',
                    'Cost': 'sum',
                    'Conversions': 'sum'
                }).reset_index()
                
                # æ´¾ç”ŸæŒ‡æ¨™ã®è¨ˆç®—
                axis_match_type_stats['CTR'] = (axis_match_type_stats['Clicks'] / axis_match_type_stats['Impressions'] * 100).round(2)
                axis_match_type_stats['CVR'] = (axis_match_type_stats['Conversions'] / axis_match_type_stats['Clicks'] * 100).round(2)
                axis_match_type_stats['CPC'] = (axis_match_type_stats['Cost'] / axis_match_type_stats['Clicks']).round(0)
                axis_match_type_stats['CPA'] = (axis_match_type_stats['Cost'] / axis_match_type_stats['Conversions']).round(0)
                
                # ãƒ©ãƒ™ãƒ«å¤‰æ›´
                axis_match_type_stats.rename(columns={'Keyword': 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°'}, inplace=True)
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
                st.session_state.category_stats = {
                    'axis': axis_stats,
                    'combination': combination_stats,
                    'cross': cross_stats,
                    'match_type': match_type_stats,
                    'axis_match_type': axis_match_type_stats
                }
        
        # åˆ†æçµæœã®è¡¨ç¤º
        stats = st.session_state.category_stats
        
        analysis_tab1, analysis_tab2, analysis_tab3, analysis_tab4, analysis_tab5 = st.tabs([
            "è»¸ã‚«ãƒ†ã‚´ãƒªåˆ†æ", "æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒªåˆ†æ", "ã‚¯ãƒ­ã‚¹åˆ†æ", "ãƒãƒƒãƒã‚¿ã‚¤ãƒ—åˆ†æ", "è©³ç´°ãƒ‡ãƒ¼ã‚¿æ¢ç´¢"
        ])
        
        with analysis_tab1:
            st.markdown("### è»¸ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹")
            
            # ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
            sort_column = st.selectbox("ä¸¦ã³æ›¿ãˆ (è»¸ã‚«ãƒ†ã‚´ãƒª)", ["Cost", "Conversions", "CPA", "CVR", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°"])
            sorted_axis_stats = stats['axis'].sort_values(sort_column, ascending=False)
            st.dataframe(sorted_axis_stats)
            
            # ã‚°ãƒ©ãƒ•
            fig1 = px.bar(
                sorted_axis_stats, 
                x='AxisCategory', 
                y='Cost', 
                color='Conversions',
                labels={'AxisCategory': 'è»¸ã‚«ãƒ†ã‚´ãƒª', 'Cost': 'ã‚³ã‚¹ãƒˆ', 'Conversions': 'ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³'},
                title='è»¸ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚³ã‚¹ãƒˆã¨ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³'
            )
            st.plotly_chart(fig1, use_container_width=True)
            
            fig2 = px.scatter(
                sorted_axis_stats, 
                x='CPA', 
                y='CVR', 
                size='Cost',
                color='AxisCategory',
                hover_data=['ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°', 'Clicks', 'Conversions'],
                labels={'CPA': 'CPA (å††)', 'CVR': 'CVR (%)', 'Cost': 'ã‚³ã‚¹ãƒˆ'},
                title='è»¸ã‚«ãƒ†ã‚´ãƒªåˆ¥ CPA vs CVR'
            )
            st.plotly_chart(fig2, use_container_width=True)
        
        with analysis_tab2:
            st.markdown("### æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹")
            
            # ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
            sort_column = st.selectbox("ä¸¦ã³æ›¿ãˆ (æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒª)", ["Cost", "Conversions", "CPA", "CVR", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°"])
            sorted_combination_stats = stats['combination'].sort_values(sort_column, ascending=False)
            st.dataframe(sorted_combination_stats)
            
            # ã‚°ãƒ©ãƒ•
            fig1 = px.bar(
                sorted_combination_stats, 
                x='CombinationCategory', 
                y='Cost', 
                color='Conversions',
                labels={'CombinationCategory': 'æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒª', 'Cost': 'ã‚³ã‚¹ãƒˆ', 'Conversions': 'ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³'},
                title='æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚³ã‚¹ãƒˆã¨ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³'
            )
            st.plotly_chart(fig1, use_container_width=True)
            
            fig2 = px.scatter(
                sorted_combination_stats, 
                x='CPA', 
                y='CVR', 
                size='Cost',
                color='CombinationCategory',
                hover_data=['ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°', 'Clicks', 'Conversions'],
                labels={'CPA': 'CPA (å††)', 'CVR': 'CVR (%)', 'Cost': 'ã‚³ã‚¹ãƒˆ'},
                title='æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒªåˆ¥ CPA vs CVR'
            )
            st.plotly_chart(fig2, use_container_width=True)
        
        with analysis_tab3:
            st.markdown("### è»¸Ã—æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒªã®ã‚¯ãƒ­ã‚¹åˆ†æ")
            
            # è¡¨ç¤ºã™ã‚‹æŒ‡æ¨™ã®é¸æŠ
            metric = st.selectbox(
                "è¡¨ç¤ºã™ã‚‹æŒ‡æ¨™", 
                ["Cost", "Conversions", "CPA", "CVR", "CTR", "CPC", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°"]
            )
            
            # ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
            pivot_df = stats['cross'].pivot_table(
                index='AxisCategory',
                columns='CombinationCategory',
                values=metric,
                aggfunc='sum'
            ).fillna(0)
            
            # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
            fig = px.imshow(
                pivot_df,
                labels=dict(x="æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒª", y="è»¸ã‚«ãƒ†ã‚´ãƒª", color=metric),
                x=pivot_df.columns,
                y=pivot_df.index,
                aspect="auto",
                title=f'è»¸Ã—æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒªåˆ¥ {metric}'
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
            st.markdown("#### ã‚¯ãƒ­ã‚¹åˆ†æãƒ‡ãƒ¼ã‚¿")
            st.dataframe(pivot_df)
        
        with analysis_tab4:
            st.markdown("### ãƒãƒƒãƒã‚¿ã‚¤ãƒ—åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹")
            
            # ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
            st.dataframe(stats['match_type'])
            
            # ã‚°ãƒ©ãƒ•
            fig1 = px.bar(
                stats['match_type'], 
                x='MatchType', 
                y='Cost', 
                color='Conversions',
                labels={'MatchType': 'ãƒãƒƒãƒã‚¿ã‚¤ãƒ—', 'Cost': 'ã‚³ã‚¹ãƒˆ', 'Conversions': 'ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³'},
                title='ãƒãƒƒãƒã‚¿ã‚¤ãƒ—åˆ¥ã‚³ã‚¹ãƒˆã¨ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³'
            )
            st.plotly_chart(fig1, use_container_width=True)
            
            # è»¸ã‚«ãƒ†ã‚´ãƒªÃ—ãƒãƒƒãƒã‚¿ã‚¤ãƒ—ã®åˆ†æ
            st.markdown("### è»¸ã‚«ãƒ†ã‚´ãƒªÃ—ãƒãƒƒãƒã‚¿ã‚¤ãƒ—")
            
            # è¡¨ç¤ºã™ã‚‹æŒ‡æ¨™ã®é¸æŠ
            metric_match = st.selectbox(
                "è¡¨ç¤ºã™ã‚‹æŒ‡æ¨™ (ãƒãƒƒãƒã‚¿ã‚¤ãƒ—)", 
                ["CPA", "CVR", "CTR", "CPC", "Cost", "Conversions", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°"]
            )
            
            # ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
            pivot_match_df = stats['axis_match_type'].pivot_table(
                index='AxisCategory',
                columns='MatchType',
                values=metric_match,
                aggfunc='sum'
            ).fillna(0)
            
            # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
            fig_match = px.imshow(
                pivot_match_df,
                labels=dict(x="ãƒãƒƒãƒã‚¿ã‚¤ãƒ—", y="è»¸ã‚«ãƒ†ã‚´ãƒª", color=metric_match),
                x=pivot_match_df.columns,
                y=pivot_match_df.index,
                aspect="auto",
                title=f'è»¸ã‚«ãƒ†ã‚´ãƒªÃ—ãƒãƒƒãƒã‚¿ã‚¤ãƒ—åˆ¥ {metric_match}'
            )
            st.plotly_chart(fig_match, use_container_width=True)
        
        with analysis_tab5:
            st.markdown("### è©³ç´°ãƒ‡ãƒ¼ã‚¿æ¢ç´¢")
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            col1, col2 = st.columns(2)
            
            with col1:
                selected_axis = st.multiselect(
                    "è»¸ã‚«ãƒ†ã‚´ãƒª",
                    options=sorted(categorized_data['AxisCategory'].unique()),
                    default=[]
                )
            
            with col2:
                selected_combination = st.multiselect(
                    "æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒª",
                    options=sorted(categorized_data['CombinationCategory'].unique()),
                    default=[]
                )
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            filtered_data = categorized_data.copy()
            
            if selected_axis:
                filtered_data = filtered_data[filtered_data['AxisCategory'].isin(selected_axis)]
            
            if selected_combination:
                filtered_data = filtered_data[filtered_data['CombinationCategory'].isin(selected_combination)]
            
            # ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
            st.dataframe(filtered_data.sort_values('Cost', ascending=False))
            
            # CSVå‡ºåŠ›ãƒœã‚¿ãƒ³
            if st.button("ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
                csv = filtered_data.to_csv(index=False)
                b64 = base64.b64encode(csv.encode()).decode()
                href = f'<a href="data:file/csv;base64,{b64}" download="filtered_keywords.csv">ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'
                st.markdown(href, unsafe_allow_html=True)

# ã‚¿ãƒ–4: ãƒ¬ãƒãƒ¼ãƒˆ
with tab4:
    st.markdown('<div class="sub-header">åˆ†æãƒ¬ãƒãƒ¼ãƒˆ</div>', unsafe_allow_html=True)
    
    if not st.session_state.is_categorized:
        st.warning("å…ˆã«ã€Œã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºã€ã‚¿ãƒ–ã§ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    elif 'category_stats' not in st.session_state or st.session_state.category_stats is None:
        st.warning("å…ˆã«ã€Œåˆ†æçµæœã€ã‚¿ãƒ–ã§åˆ†æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    else:
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        stats = st.session_state.category_stats
        categorized_data = st.session_state.categorized_data
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒœã‚¿ãƒ³
        if st.button("AIã‚’ä½¿ã£ã¦åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"):
            if not st.session_state.api_key:
                st.error("OpenAI API KeyãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šã—ã¦ãã ã•ã„ã€‚")
            else:
                with st.spinner("ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­..."):
                    try:
                        # APIæ¥ç¶šãƒ†ã‚¹ãƒˆ
                        try:
                            client = OpenAI(api_key=st.session_state.api_key)
                            test_response = client.chat.completions.create(
                                model="gpt-3.5-turbo",
                                messages=[{"role": "user", "content": "ãƒ†ã‚¹ãƒˆ"}],
                                max_tokens=5
                            )
                            debug_info(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå‰ã®APIæ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ: {test_response.choices[0].message.content}")
                        except Exception as e:
                            st.error(f"APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}")
                            st.stop()
                            
                        # åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
                        axis_stats_str = stats['axis'].sort_values('Cost', ascending=False).head(10).to_string()
                        combination_stats_str = stats['combination'].sort_values('Cost', ascending=False).head(10).to_string()
                        match_type_stats_str = stats['match_type'].to_string()
                        
                        # é«˜åŠ¹ç‡ã‚«ãƒ†ã‚´ãƒªã¨ä½åŠ¹ç‡ã‚«ãƒ†ã‚´ãƒªã®æŠ½å‡º
                        high_perf_axis = stats['axis'][stats['axis']['Conversions'] >= 5].sort_values('CPA').head(3)
                        low_perf_axis = stats['axis'][stats['axis']['Conversions'] >= 5].sort_values('CPA', ascending=False).head(3)
                        
                        high_perf_axis_str = high_perf_axis.to_string()
                        low_perf_axis_str = low_perf_axis.to_string()
                        
                        # OpenAI APIã§ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
                        client = OpenAI(api_key=st.session_state.api_key)
                        
                        prompt = f"""
ã‚ãªãŸã¯ãƒªã‚¹ãƒ†ã‚£ãƒ³ã‚°åºƒå‘Šã®åˆ†æå°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã‚µãƒ¼ãƒ“ã‚¹æ¦‚è¦:
{st.session_state.service_description}

===== è»¸ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼ˆã‚³ã‚¹ãƒˆä¸Šä½10ã‚«ãƒ†ã‚´ãƒªï¼‰ =====
{axis_stats_str}

===== æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼ˆã‚³ã‚¹ãƒˆä¸Šä½10ã‚«ãƒ†ã‚´ãƒªï¼‰ =====
{combination_stats_str}

===== ãƒãƒƒãƒã‚¿ã‚¤ãƒ—åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ =====
{match_type_stats_str}

===== é«˜åŠ¹ç‡è»¸ã‚«ãƒ†ã‚´ãƒªï¼ˆCPAä½é †ï¼‰ =====
{high_perf_axis_str}

===== ä½åŠ¹ç‡è»¸ã‚«ãƒ†ã‚´ãƒªï¼ˆCPAé«˜é †ï¼‰ =====
{low_perf_axis_str}

ãƒ¬ãƒãƒ¼ãƒˆå½¢å¼:
1. å…¨ä½“ã‚µãƒãƒªãƒ¼ - ä¸»è¦ãªå‚¾å‘ã¨ç™ºè¦‹ç‚¹ã®æ¦‚è¦
2. è»¸ã‚«ãƒ†ã‚´ãƒªã®åˆ†æ - æœ€ã‚‚åŠ¹æœçš„ãªã‚«ãƒ†ã‚´ãƒªã¨æœ€é©åŒ–ãŒå¿…è¦ãªã‚«ãƒ†ã‚´ãƒª
3. æ›ã‘åˆã‚ã›ã‚«ãƒ†ã‚´ãƒªã®åˆ†æ - ãƒ¦ãƒ¼ã‚¶ãƒ¼æ„å›³ã«é–¢ã™ã‚‹æ´å¯Ÿ
4. ãƒãƒƒãƒã‚¿ã‚¤ãƒ—ã®æœ€é©åŒ– - ãƒãƒƒãƒã‚¿ã‚¤ãƒ—åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ææ¡ˆ
5. æœ€é©åŒ–ææ¡ˆ - å…·ä½“çš„ãªæ”¹å–„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆ3ã¤ï¼‰

åˆ†æã™ã‚‹ãƒã‚¤ãƒ³ãƒˆ:
- ã‚³ã‚¹ãƒˆåŠ¹ç‡ï¼ˆCPAï¼‰ã®è‰¯ã„ã‚«ãƒ†ã‚´ãƒªã¨æ‚ªã„ã‚«ãƒ†ã‚´ãƒªã®å‚¾å‘
- ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç‡ï¼ˆCVRï¼‰ã«å½±éŸ¿ã‚’ä¸ãˆã¦ã„ã‚‹è¦ç´ 
- äºˆç®—é…åˆ†ã®æœ€é©åŒ–æ–¹æ³•
- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®è¿½åŠ ã‚„é™¤å¤–ã®ææ¡ˆ
"""
                        
                        debug_info("ãƒ¬ãƒãƒ¼ãƒˆç”ŸæˆAPIãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Ÿè¡Œ")
                        
                        response = client.chat.completions.create(
                            model="gpt-4-turbo",
                            messages=[
                                {"role": "system", "content": "You are a PPC advertising specialist with deep expertise in keyword analysis."},
                                {"role": "user", "content": prompt}
                            ],
                            max_tokens=4000,
                            temperature=0.5
                        )
                        
                        report = response.choices[0].message.content
                        
                        debug_info(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {len(report)}æ–‡å­—")
                        
                        # ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
                        st.markdown("## ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
                        st.markdown(report)
                        
                        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã¨å…±æœ‰ãƒªãƒ³ã‚¯
                        csv = categorized_data.to_csv(index=False)
                        b64 = base64.b64encode(csv.encode()).decode()
                        download_link = f'<a href="data:file/csv;base64,{b64}" download="categorized_keywords.csv" class="download-button">ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºæ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'
                        st.markdown(download_link, unsafe_allow_html=True)
                        
                    except Exception as e:
                        st.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                        st.exception(e)
        else:
            st.info("ã€ŒAIã‚’ä½¿ã£ã¦åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸè©³ç´°ãªåˆ†æãƒ¬ãƒãƒ¼ãƒˆãŒç”Ÿæˆã•ã‚Œã¾ã™ã€‚")
            
            # ã‚µãƒ³ãƒ—ãƒ«å¯è¦–åŒ–ã®è¡¨ç¤º
            st.markdown("### ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å¯è¦–åŒ–ä¾‹")
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒƒãƒ—ã®è¡¨ç¤º
            col1, col2 = st.columns(2)
            
            with col1:
                # ã‚³ã‚¹ãƒˆåˆ†å¸ƒã€ã‚¨ãƒ©ãƒ¼å‡¦ç†ã‚’å¼·åŒ–
                try:
                    # ãƒˆãƒªãƒ¼ãƒãƒƒãƒ—ä½œæˆå‰ã«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    treemap_data = categorized_data.copy()
                    treemap_data = treemap_data[treemap_data['Keyword'].notna() & (treemap_data['Keyword'] != '')]
                    
                    # NaNå€¤ã‚’æŒã¤è¡Œã‚„è¨ˆç®—æŒ‡æ¨™ãŒNaNã®è¡Œã‚‚é™¤å¤–
                    treemap_data = treemap_data.dropna(subset=['Cost', 'CVR'])
                    
                    # ãƒ‡ãƒ¼ã‚¿ãŒååˆ†ã«ã‚ã‚‹ã‹ç¢ºèª
                    if len(treemap_data) > 0:
                        fig = px.treemap(
                            treemap_data,
                            path=['AxisCategory', 'CombinationCategory', 'Keyword'],
                            values='Cost',
                            color='CVR',
                            color_continuous_scale='RdYlGn',
                            title='ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚³ã‚¹ãƒˆåˆ†å¸ƒ (CVRã§ã‚«ãƒ©ãƒ¼è¡¨ç¤º)'
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.warning("ãƒ„ãƒªãƒ¼ãƒãƒƒãƒ—ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
                        
                        # ä»£æ›¿ã®å¯è¦–åŒ–ã‚’è¡¨ç¤º
                        alt_fig = px.bar(
                            stats['axis'].sort_values('Cost', ascending=False).head(10),
                            x='AxisCategory',
                            y='Cost',
                            color='CVR',
                            title='ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚³ã‚¹ãƒˆåˆ†å¸ƒï¼ˆä¸Šä½10ã‚«ãƒ†ã‚´ãƒªï¼‰'
                        )
                        st.plotly_chart(alt_fig, use_container_width=True)
                
                except ValueError as ve:
                    st.error(f"ãƒ„ãƒªãƒ¼ãƒãƒƒãƒ—ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(ve)}")
                    
                    # ä»£æ›¿ã®å¯è¦–åŒ–ã‚’è¡¨ç¤º
                    st.info("ä»£æ›¿ã®å¯è¦–åŒ–ã‚’è¡¨ç¤ºã—ã¾ã™")
                    
                    # æ¨ªæ£’ã‚°ãƒ©ãƒ•ã§ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚³ã‚¹ãƒˆè¡¨ç¤º
                    alt_fig = px.bar(
                        stats['axis'].sort_values('Cost', ascending=False).head(10),
                        x='Cost',
                        y='AxisCategory',
                        orientation='h',
                        color='CVR',
                        title='è»¸ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚³ã‚¹ãƒˆåˆ†å¸ƒï¼ˆä¸Šä½10ã‚«ãƒ†ã‚´ãƒªï¼‰'
                    )
                    st.plotly_chart(alt_fig, use_container_width=True)
                
                except Exception as e:
                    st.error(f"å¯è¦–åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                    st.warning("å€‹åˆ¥ã®åˆ†æã‚¿ãƒ–ã§è©³ç´°ãªãƒ‡ãƒ¼ã‚¿ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
            
            with col2:
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒƒãƒ— - ã“ã¡ã‚‰ã‚‚å¿µã®ãŸã‚ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°è¿½åŠ 
                try:
                    # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    scatter_data = categorized_data[categorized_data['Clicks'] > min_clicks].copy()
                    
                    # NaNå€¤ã‚’ãƒ‰ãƒ­ãƒƒãƒ—
                    scatter_data = scatter_data.dropna(subset=['CPA', 'CVR', 'Cost', 'AxisCategory'])
                    
                    if len(scatter_data) > 0:
                        fig = px.scatter(
                            scatter_data,
                            x='CPA',
                            y='CVR',
                            size='Cost',
                            color='AxisCategory',
                            hover_name='Keyword',
                            log_x=True,
                            title='ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒƒãƒ—'
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.warning("æ•£å¸ƒå›³ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
                        
                        # ä»£æ›¿ã®æ•£å¸ƒå›³ã‚’å˜ç´”åŒ–ã—ã¦è¡¨ç¤º
                        simple_fig = px.scatter(
                            stats['axis'],
                            x='CPA',
                            y='CVR',
                            size='Cost',
                            color='AxisCategory',
                            title='ã‚«ãƒ†ã‚´ãƒªãƒ¬ãƒ™ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒƒãƒ—'
                        )
                        st.plotly_chart(simple_fig, use_container_width=True)
                        
                except Exception as e:
                    st.error(f"æ•£å¸ƒå›³ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                    
                    # ä»£æ›¿ã®è¦–è¦šåŒ–
                    try:
                        simple_fig = px.scatter(
                            stats['axis'],
                            x='CPA',
                            y='CVR',
                            size='Cost',
                            title='ã‚«ãƒ†ã‚´ãƒªãƒ¬ãƒ™ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒƒãƒ—'
                        )
                        st.plotly_chart(simple_fig, use_container_width=True)
                    except:
                        st.warning("ãƒ‡ãƒ¼ã‚¿ã®è¦–è¦šåŒ–ãŒã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å€‹åˆ¥ã®åˆ†æã‚¿ãƒ–ã§è©³ç´°ãªæƒ…å ±ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
            
            # ã‚¯ã‚¤ãƒƒã‚¯æ´å¯Ÿ
            st.markdown("### ã‚¯ã‚¤ãƒƒã‚¯æ´å¯Ÿ")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # é«˜åŠ¹ç‡ã‚«ãƒ†ã‚´ãƒª
                try:
                    high_performing = stats['axis'][
                        (stats['axis']['Conversions'] > 0) & 
                        (stats['axis']['ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°'] >= 3)
                    ].nsmallest(5, 'CPA')
                    
                    st.markdown("#### æœ€ã‚‚åŠ¹ç‡ã®è‰¯ã„è»¸ã‚«ãƒ†ã‚´ãƒª (CPAé †)")
                    st.dataframe(high_performing[['AxisCategory', 'Cost', 'Conversions', 'CPA', 'CVR']])
                except Exception as e:
                    st.warning(f"åŠ¹ç‡ã®è‰¯ã„ã‚«ãƒ†ã‚´ãƒªã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            
            with col2:
                # ä½åŠ¹ç‡ã‚«ãƒ†ã‚´ãƒª
                try:
                    low_performing = stats['axis'][
                        (stats['axis']['Conversions'] > 0) & 
                        (stats['axis']['Cost'] > kw_min_cost) & 
                        (stats['axis']['ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°'] >= 3)
                    ].nlargest(5, 'CPA')
                    
                    st.markdown("#### åŠ¹ç‡æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚‹è»¸ã‚«ãƒ†ã‚´ãƒª (CPAé™é †)")
                    st.dataframe(low_performing[['AxisCategory', 'Cost', 'Conversions', 'CPA', 'CVR']])
                except Exception as e:
                    st.warning(f"æ”¹å–„å€™è£œã‚«ãƒ†ã‚´ãƒªã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            
            # åˆ†æäº‹ä¾‹
            st.markdown("### åˆ†æä¾‹")
            st.markdown("""
            #### ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æœ€é©åŒ–ã«å‘ã‘ãŸä¸€èˆ¬çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
            1. **åŠ¹ç‡ã®è‰¯ã„ã‚«ãƒ†ã‚´ãƒªã¸ã®äºˆç®—ã‚·ãƒ•ãƒˆ**
               - é«˜CVRãƒ»ä½CPAã®ã‚«ãƒ†ã‚´ãƒªã‚’ç‰¹å®šã—ã€å…¥æœ­å˜ä¾¡ã‚’èª¿æ•´
               - ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒè¦‹è¾¼ã‚ã‚‹ã‚«ãƒ†ã‚´ãƒªã¸ã®äºˆç®—æœ€é©åŒ–
            
            2. **ä½åŠ¹ç‡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ”¹å–„ã¾ãŸã¯é™¤å¤–**
               - é«˜ã‚³ã‚¹ãƒˆãƒ»ä½ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç‰¹å®š
               - ãƒãƒƒãƒã‚¿ã‚¤ãƒ—ã®èª¿æ•´ã‚„é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®è¿½åŠ ã‚’æ¤œè¨
            
            3. **æ–°è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ç™ºè¦‹**
               - åŠ¹ç‡ã®è‰¯ã„ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰ã®ã‚¢ã‚¤ãƒ‡ã‚¢æŠ½å‡º
               - ç«¶åˆåˆ†æã«ã‚ˆã‚‹æ–°è¦é–‹æ‹“
            """)

# ãƒãƒƒãƒ”ãƒ³ã‚°æƒ…å ±ã®ãƒ•ãƒƒã‚¿ãƒ¼ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
if DEBUG and st.session_state.column_mapping is not None:
    with st.expander("ğŸ” ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°æƒ…å ±", expanded=False):
        st.json(st.session_state.column_mapping)

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("ãƒªã‚¹ãƒ†ã‚£ãƒ³ã‚°åºƒå‘Šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã‚·ã‚¹ãƒ†ãƒ  | Ver 1.0")